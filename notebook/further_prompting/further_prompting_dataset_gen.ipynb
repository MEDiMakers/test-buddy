{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "from tqdm import trange\n",
    "import json\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from groq import Groq\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "## load env variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\n",
    "CHAT_MODEL   = \"llama3-70b-8192\"\n",
    "client = Groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_BAD_HUMAN_ANSWERS = \\\n",
    "'''You are an expert in linguistic variation and medical communication. \n",
    "Take it that the answer provided is a 10/10 answer. \n",
    "Your task is to generate 5 poor answers that would be of a 3/10 quality for a given question-answer pair. \n",
    "\n",
    "Given Question:\n",
    "{qn}\n",
    "Given Answer:\n",
    "{ans}\n",
    "\n",
    "Example return format:\n",
    "{{\"3/10\" : [\"poor answer 1\",\"poor answer 2\",\"poor answer 3\",\"poor answer 4\",\"poor answer 5\"]}}\n",
    "Ensure and double check that the answer follows the format above strictly.\n",
    "'''\n",
    "\n",
    "def extract_poor_answer(input_string):\n",
    "    # Find the start and end indices of the JSON data within the input string\n",
    "    # Assuming the JSON data starts with '{' and ends with '}'\n",
    "    json_start = input_string.find('{')\n",
    "    json_end = input_string.rfind('}') + 1\n",
    "    \n",
    "    # If either the start or end index is not found, raise an error\n",
    "    if json_start == -1 or json_end == -1:\n",
    "        raise ValueError(\"Invalid input: No JSON data found.\")\n",
    "\n",
    "    # Extract the substring that potentially contains the JSON data\n",
    "    json_data = input_string[json_start:json_end]\n",
    "    \n",
    "    try:\n",
    "        # Attempt to convert the JSON string to a Python dictionary\n",
    "        data_dict = json.loads(json_data)\n",
    "        return data_dict\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        # If JSON decoding fails, search for a JSON object containing the 'questions' key\n",
    "        # Using regex to match a pattern that includes the 'questions' key\n",
    "        pattern = r'{\"3/10\":\\s*\\[.*?\\]}'\n",
    "        match = re.search(pattern, input_string, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "            # If a match is found, extract the matched JSON string and convert it to a dictionary\n",
    "            data_json_str = match.group(0)\n",
    "            data_dict = json.loads(data_json_str)\n",
    "            return data_dict\n",
    "\n",
    "        # If no valid JSON is found, the function will Log an error\n",
    "        else:\n",
    "            logging.error(\"No dictionary with '3/10' as a key found in this input string. Error by LLM\")\n",
    "            return {\"error\": \"No dictionary with '3/10' found\"}\n",
    "        \n",
    "\n",
    "def generate_poor_answers(question, answer, client):\n",
    "    # Prepare the prompt using the provided answer prompt template, text, and list of questions\n",
    "    prompt = PromptTemplate(\n",
    "        template=GENERATE_BAD_HUMAN_ANSWERS,\n",
    "        input_variables=[\"query\", \"document\"],\n",
    "    ) \n",
    "    \n",
    "    # Format the final prompt with the actual text data and question list\n",
    "    final_prompt = prompt.format(qn=question, ans=answer)\n",
    "\n",
    "    # Generate the completion by interacting with the language model API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": final_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,  # Control the randomness of the output (lower means less random)\n",
    "        max_tokens=1024,  # Limit the response length\n",
    "        top_p=1,  # Nucleus sampling parameter (1 means only the most likely tokens are considered)\n",
    "        stream=True,  # Enable streaming of the response chunks\n",
    "        stop=None,  # Define stopping conditions (None means no stopping condition)\n",
    "    )\n",
    "\n",
    "    # Initialize an empty string to accumulate the response content\n",
    "    answer = ''''''\n",
    "    for chunk in completion:\n",
    "        # Append each chunk of content to the answer string\n",
    "        answer += chunk.choices[0].delta.content or \"\"\n",
    "    cleaned_answer = extract_poor_answer(answer)\n",
    "    # Return the dictionary containing the generated answers\n",
    "    return cleaned_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_SATISFACTORY_HUMAN_ANSWERS = \\\n",
    "'''You are an expert in linguistic variation and medical communication. \n",
    "Take it that the answer provided is a 10/10 answer. \n",
    "Your task is to generate 5 satisfactory answers that would be of a 6/10 quality for a given question-answer pair. \n",
    "\n",
    "Given Question:\n",
    "{qn}\n",
    "Given Answer:\n",
    "{ans}\n",
    "\n",
    "Example return format:\n",
    "{{\"6/10\" : [\"satisfactory answer 1\",\"satisfactory answer 2\",\"satisfactory answer 3\",\"satisfactory answer 4\",\"satisfactory answer 5\"]}}\n",
    "Ensure and double check that the answer follows the format above strictly.\n",
    "'''\n",
    "\n",
    "def extract_satisfactory_answer(input_string):\n",
    "    # Find the start and end indices of the JSON data within the input string\n",
    "    # Assuming the JSON data starts with '{' and ends with '}'\n",
    "    json_start = input_string.find('{')\n",
    "    json_end = input_string.rfind('}') + 1\n",
    "    \n",
    "    # If either the start or end index is not found, raise an error\n",
    "    if json_start == -1 or json_end == -1:\n",
    "        raise ValueError(\"Invalid input: No JSON data found.\")\n",
    "\n",
    "    # Extract the substring that potentially contains the JSON data\n",
    "    json_data = input_string[json_start:json_end]\n",
    "    \n",
    "    try:\n",
    "        # Attempt to convert the JSON string to a Python dictionary\n",
    "        data_dict = json.loads(json_data)\n",
    "        return data_dict\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        # If JSON decoding fails, search for a JSON object containing the 'questions' key\n",
    "        # Using regex to match a pattern that includes the 'questions' key\n",
    "        pattern = r'{\"6/10\":\\s*\\[.*?\\]}'\n",
    "        match = re.search(pattern, input_string, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "            # If a match is found, extract the matched JSON string and convert it to a dictionary\n",
    "            data_json_str = match.group(0)\n",
    "            data_dict = json.loads(data_json_str)\n",
    "            return data_dict\n",
    "\n",
    "        # If no valid JSON is found, the function will Log an error\n",
    "        else:\n",
    "            logging.error(\"No dictionary with '6/10' as a key found in this input string. Error by LLM\")\n",
    "            return {\"error\": \"No dictionary with '6/10' found\"}\n",
    "        \n",
    "\n",
    "def generate_satisfactory_answers(question, answer, client):\n",
    "    # Prepare the prompt using the provided answer prompt template, text, and list of questions\n",
    "    prompt = PromptTemplate(\n",
    "        template=GENERATE_SATISFACTORY_HUMAN_ANSWERS,\n",
    "        input_variables=[\"query\", \"document\"],\n",
    "    ) \n",
    "    \n",
    "    # Format the final prompt with the actual text data and question list\n",
    "    final_prompt = prompt.format(qn=question, ans=answer)\n",
    "\n",
    "    # Generate the completion by interacting with the language model API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": final_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,  # Control the randomness of the output (lower means less random)\n",
    "        max_tokens=1024,  # Limit the response length\n",
    "        top_p=1,  # Nucleus sampling parameter (1 means only the most likely tokens are considered)\n",
    "        stream=True,  # Enable streaming of the response chunks\n",
    "        stop=None,  # Define stopping conditions (None means no stopping condition)\n",
    "    )\n",
    "\n",
    "    # Initialize an empty string to accumulate the response content\n",
    "    answer = ''''''\n",
    "    for chunk in completion:\n",
    "        # Append each chunk of content to the answer string\n",
    "        answer += chunk.choices[0].delta.content or \"\"\n",
    "    cleaned_answer = extract_satisfactory_answer(answer)\n",
    "    # Return the dictionary containing the generated answers\n",
    "    return cleaned_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_GOOD_HUMAN_ANSWERS = \\\n",
    "'''You are an expert in linguistic variation and medical communication. \n",
    "Take it that the answer provided is a 10/10 answer. \n",
    "Your task is to generate 5 good answers that would be of a 8.5/10 quality for a given question-answer pair. \n",
    "\n",
    "Given Question:\n",
    "{qn}\n",
    "Given Answer:\n",
    "{ans}\n",
    "\n",
    "Example return format:\n",
    "{{\"8.5/10\" : [\"good answer 1\",\"good answer 2\",\"good answer 3\",\"good answer 4\",\"good answer 5\"]}}\n",
    "Ensure and double check that the answer follows the format above strictly.\n",
    "'''\n",
    "\n",
    "def extract_good_answer(input_string):\n",
    "    # Find the start and end indices of the JSON data within the input string\n",
    "    # Assuming the JSON data starts with '{' and ends with '}'\n",
    "    json_start = input_string.find('{')\n",
    "    json_end = input_string.rfind('}') + 1\n",
    "    \n",
    "    # If either the start or end index is not found, raise an error\n",
    "    if json_start == -1 or json_end == -1:\n",
    "        raise ValueError(\"Invalid input: No JSON data found.\")\n",
    "\n",
    "    # Extract the substring that potentially contains the JSON data\n",
    "    json_data = input_string[json_start:json_end]\n",
    "    \n",
    "    try:\n",
    "        # Attempt to convert the JSON string to a Python dictionary\n",
    "        data_dict = json.loads(json_data)\n",
    "        return data_dict\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        # If JSON decoding fails, search for a JSON object containing the 'questions' key\n",
    "        # Using regex to match a pattern that includes the 'questions' key\n",
    "        pattern = r'{\"8.5/10\":\\s*\\[.*?\\]}'\n",
    "        match = re.search(pattern, input_string, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "            # If a match is found, extract the matched JSON string and convert it to a dictionary\n",
    "            data_json_str = match.group(0)\n",
    "            data_dict = json.loads(data_json_str)\n",
    "            return data_dict\n",
    "\n",
    "        # If no valid JSON is found, the function will Log an error\n",
    "        else:\n",
    "            logging.error(\"No dictionary with '8.5/10' as a key found in this input string. Error by LLM\")\n",
    "            return {\"error\": \"No dictionary with '8.5/10' found\"}\n",
    "        \n",
    "\n",
    "def generate_good_answers(question, answer, client):\n",
    "    # Prepare the prompt using the provided answer prompt template, text, and list of questions\n",
    "    prompt = PromptTemplate(\n",
    "        template=GENERATE_GOOD_HUMAN_ANSWERS,\n",
    "        input_variables=[\"query\", \"document\"],\n",
    "    ) \n",
    "    \n",
    "    # Format the final prompt with the actual text data and question list\n",
    "    final_prompt = prompt.format(qn=question, ans=answer)\n",
    "\n",
    "    # Generate the completion by interacting with the language model API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": final_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,  # Control the randomness of the output (lower means less random)\n",
    "        max_tokens=1024,  # Limit the response length\n",
    "        top_p=1,  # Nucleus sampling parameter (1 means only the most likely tokens are considered)\n",
    "        stream=True,  # Enable streaming of the response chunks\n",
    "        stop=None,  # Define stopping conditions (None means no stopping condition)\n",
    "    )\n",
    "\n",
    "    # Initialize an empty string to accumulate the response content\n",
    "    answer = ''''''\n",
    "    for chunk in completion:\n",
    "        # Append each chunk of content to the answer string\n",
    "        answer += chunk.choices[0].delta.content or \"\"\n",
    "    cleaned_answer = extract_good_answer(answer)\n",
    "    # Return the dictionary containing the generated answers\n",
    "    return cleaned_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    with open(\"../../data/synthetically_generated_qa_pairs.json\", \"r\", encoding='utf-8') as fin:\n",
    "        pairs = json.load(fin)\n",
    "\n",
    "    for i in range(len(pairs)):\n",
    "        question = pairs[i]['Question']\n",
    "        answer = pairs[i]['Answer']\n",
    "        pairs[i]['3/10'] = generate_poor_answers(question, answer, client).get(\"3/10\")\n",
    "        pairs[i]['6/10'] = generate_satisfactory_answers(question, answer, client).get(\"6/10\")\n",
    "        pairs[i]['8.5/10'] = generate_good_answers(question, answer, client).get(\"8.5/10\")\n",
    "            \n",
    "        with open(\"../../data/further_prompting/QA_pairs_with_answer_range.json\", \"w\", encoding='utf-8') as fout:\n",
    "                json.dump(pairs, fout, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        if i > 3 and i % 3 == 0:\n",
    "            print(\"Sleeping now...\")\n",
    "            time.sleep(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_buddy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
