{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from groq import Groq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODIFIED CODE TO REVAMP AND RUN VIA GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here\n",
      " is\n",
      " the\n",
      " refined\n",
      " text\n",
      " with\n",
      " abbrev\n",
      "iations\n",
      " expanded\n",
      ":\n",
      "\n",
      "\n",
      "'\n",
      "Check\n",
      " for\n",
      " normal\n",
      " breathing\n",
      " and\n",
      " pulse\n",
      " after\n",
      " every\n",
      " \n",
      "5\n",
      " cycles\n",
      " of\n",
      " Card\n",
      "i\n",
      "op\n",
      "ul\n",
      "monary\n",
      " Res\n",
      "usc\n",
      "itation\n",
      " (\n",
      "C\n",
      "PR\n",
      ")\n",
      " \n",
      "30\n",
      ":\n",
      "2\n",
      ".\n",
      " If\n",
      " normal\n",
      " breathing\n",
      " and\n",
      " pulse\n",
      " are\n",
      " absent\n",
      " or\n",
      " you\n",
      " are\n",
      " unsure\n",
      ",\n",
      " continue\n",
      " Card\n",
      "i\n",
      "op\n",
      "ul\n",
      "monary\n",
      " Res\n",
      "usc\n",
      "itation\n",
      " (\n",
      "C\n",
      "PR\n",
      ")\n",
      " \n",
      "30\n",
      ":\n",
      "2\n",
      ".\n",
      " If\n",
      " pulse\n",
      " is\n",
      " present\n",
      " and\n",
      " normal\n",
      " breathing\n",
      " is\n",
      " absent\n",
      ",\n",
      " perform\n",
      " rescue\n",
      " breathing\n",
      " at\n",
      " a\n",
      " rate\n",
      " of\n",
      " \n",
      "30\n",
      " breath\n",
      "s\n",
      " per\n",
      " minute\n",
      " (\n",
      "one\n",
      " breath\n",
      " every\n",
      " \n",
      "2\n",
      " seconds\n",
      ")\n",
      " by\n",
      " giving\n",
      " one\n",
      " breath\n",
      " and\n",
      " counting\n",
      " \n",
      "2\n",
      "-a\n",
      "-th\n",
      "ousand\n",
      ".\n",
      " Re\n",
      "-ass\n",
      "ess\n",
      " for\n",
      " normal\n",
      " breathing\n",
      " and\n",
      " pulse\n",
      " after\n",
      " \n",
      "30\n",
      " breath\n",
      "s\n",
      ".\n",
      " If\n",
      " both\n",
      " the\n",
      " breathing\n",
      " and\n",
      " pulse\n",
      " are\n",
      " present\n",
      ",\n",
      " position\n",
      " the\n",
      " casualty\n",
      " in\n",
      " the\n",
      " sup\n",
      "ine\n",
      " position\n",
      " and\n",
      " continuously\n",
      " monitor\n",
      " the\n",
      " casualty\n",
      " until\n",
      " help\n",
      " arrives\n",
      ".\n",
      " If\n",
      " there\n",
      " are\n",
      " \n",
      "2\n",
      " trained\n",
      " healthcare\n",
      " providers\n",
      " The\n",
      " ratio\n",
      " of\n",
      " chest\n",
      " compress\n",
      "ions\n",
      " to\n",
      " ventil\n",
      "ations\n",
      " is\n",
      " \n",
      "15\n",
      ":\n",
      "2\n",
      ".\n",
      " Perform\n",
      " \n",
      "10\n",
      " cycles\n",
      " of\n",
      " \n",
      "15\n",
      " compress\n",
      "ions\n",
      " and\n",
      " \n",
      "2\n",
      " ventil\n",
      "ations\n",
      " within\n",
      " \n",
      "2\n",
      " minutes\n",
      ".\n",
      " Continue\n",
      " to\n",
      " perform\n",
      " Card\n",
      "i\n",
      "op\n",
      "ul\n",
      "monary\n",
      " Res\n",
      "usc\n",
      "itation\n",
      " (\n",
      "C\n",
      "PR\n",
      ")\n",
      " until\n",
      ":\n",
      " Param\n",
      "edic\n",
      " takes\n",
      " over\n",
      " from\n",
      " resc\n",
      "uer\n",
      ";\n",
      " or\n",
      " Automated\n",
      " External\n",
      " Def\n",
      "ibr\n",
      "illator\n",
      " (\n",
      "A\n",
      "ED\n",
      ")\n",
      " prompts\n",
      " to\n",
      " analyse\n",
      " the\n",
      " casualty\n",
      "â€™s\n",
      " heart\n",
      " rhythm\n",
      ",\n",
      " is\n",
      " charging\n",
      " or\n",
      " when\n",
      " shock\n",
      " is\n",
      " to\n",
      " be\n",
      " delivered\n",
      ";\n",
      " or\n",
      " Casual\n",
      "ty\n",
      " wakes\n",
      " up\n",
      " or\n",
      " reg\n",
      "ains\n",
      " normal\n",
      " breathing\n",
      ".\n",
      " Keep\n",
      " casualty\n",
      " in\n",
      " the\n",
      " same\n",
      " (\n",
      "sup\n",
      "ine\n",
      ")\n",
      " position\n",
      " and\n",
      " continue\n",
      " to\n",
      " monitor\n",
      " the\n",
      " casualty\n",
      " until\n",
      " help\n",
      " arrives\n",
      ".\n",
      " Healthcare\n",
      " providers\n",
      " who\n",
      " are\n",
      " trained\n",
      " and\n",
      " confident\n",
      " in\n",
      " pulse\n",
      " check\n",
      " should\n",
      " check\n",
      " the\n",
      " pulse\n",
      " after\n",
      " at\n",
      " least\n",
      " five\n",
      " cycles\n",
      " of\n",
      " \n",
      "30\n",
      " compress\n",
      "ions\n",
      " to\n",
      " two\n",
      " ventil\n",
      "ations\n",
      " (\n",
      "done\n",
      " via\n",
      " a\n",
      " bag\n",
      "-val\n",
      "ve\n",
      " mask\n",
      ").\n",
      " Checking\n",
      " of\n",
      " pulse\n",
      " should\n",
      " not\n",
      " take\n",
      " more\n",
      " than\n",
      " '\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Code to read one text file and transform it to a json file, just do a loop over ur own folder \n",
    "number = str(76)\n",
    "\n",
    "file_path = '../data/page_texts/6_wenyeong/page_' + number + '.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    page_content = file.read()\n",
    "    # Append the content to the list\n",
    "    # print(page_content)\n",
    "\n",
    "page_dict = {'page_' + number: {}}\n",
    "page_dict['page_' + number]['Page'] = int(file_path.split(\"/\")[-1].split(\".\")[0][-2:])\n",
    "GROQ_API_KEY = \"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\"\n",
    "client = Groq(api_key = GROQ_API_KEY)\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI assistant specializing in medical text cleaning for a Singaporean hospital's nursing manual. Your task is to expand abbreviations and clarify medical jargon. When presented with a piece of text, you will return the cleaned version with every abbreviation expanded.\\n\\nInstructions:\\n1. Expand all medical abbreviations in the text.\\n2. Maintain the original text structure and formatting.\\n3. Place expanded terms in parentheses immediately after the original abbreviation.\\n4. Do not alter medical terms that are not abbreviations.\\n5. If an abbreviation is unclear or could have multiple meanings, choose the most likely expansion based on the context.\\n6. At the end of the cleaned text, provide a list of all abbreviations you expanded and their full forms.\\n\\nExample input: \\\"The pt presented with SOB and was admitted to the ICU.\\\"\\nExample output: \\\"The pt (patient) presented with SOB (shortness of breath) and was admitted to the ICU (Intensive Care Unit).\\n\\nList of expansions:\\n- pt: patient\\n- SOB: shortness of breath\\n- ICU: Intensive Care Unit\\\"\\n\\nAs this is a JSON that I will parse, you WILL INCLUDE '\\n' in areas where there is a new line required. Lastly, ensure that the word 'Figure' or any relationship to Figures. e.g. (Figure 7-17)  are removed from the text. \\\n",
    "            You do NOT need to give the list of expansions. Just give the refined text. No note is required . This is the text. \\n \\\n",
    "            \" + page_content  \n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "# for chunk in completion:\n",
    "#     print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "\n",
    "cleaned_text = \"\"\n",
    "for chunk in completion:\n",
    "    y = chunk.choices[0].delta.content\n",
    "    print(y)\n",
    "    cleaned_text += (y  or \"\")\n",
    "\n",
    "page_dict['page_' + number]['Text'] = cleaned_text\n",
    "\n",
    "json_file_path = '../data/cleaned_pages/6_wenyeong/page_' + number + '.json'\n",
    "os.makedirs(os.path.dirname(json_file_path), exist_ok=True)\n",
    "\n",
    "# Write the dictionary to a JSON file\n",
    "with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(page_dict,json_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a SYS prompt that should remove the text \"Figure 7-17\":\n",
      "\n",
      "`:%s/\"Figure 7-17\"//g`\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "* `:%s/` starts a global substitution command\n",
      "* `\"Figure 7-17\"` is the text to be replaced (note the quotes to match the exact text)\n",
      "* `//` is the replacement text (empty, meaning delete the original text)\n",
      "* `g` flag at the end makes the substitution global, so it will remove all occurrences of the text in the file."
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key = GROQ_API_KEY)\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I need a SYS prompt to remove this \\n\\n\\\"Figure 7-17\\\"\\n\\n\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
