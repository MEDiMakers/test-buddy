{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for generating a question to further prompt the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from tqdm import trange\n",
    "import time\n",
    "import re\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "## load env variables\n",
    "GROQ_API_KEY       = os.environ[\"GROQ_API_KEY\"]\n",
    "CHAT_MODEL         = \"llama3-70b-8192\"\n",
    "client = Groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QA_pair_number': 0,\n",
       " 'Question': 'What is the percentage of total mortality in Singapore attributed to ischemic heart disease, based on national health statistics from the Ministry of Health in 2019?',\n",
       " 'Answer': 'Ischemic heart disease contributes to 18.8% of total mortality in Singapore, based on national health statistics from the Ministry of Health in 2019.',\n",
       " '3/10': [\"I think it's around 20% or something, I'm not really sure.\",\n",
       "  \"Ischemic heart disease is a big deal in Singapore, but I don't have the exact number.\",\n",
       "  \"Heart disease is a major killer in Singapore, but I'm not sure what the exact percentage is.\",\n",
       "  \"I'm pretty sure it's higher than 10%, but I don't have the exact stat.\",\n",
       "  \"Singapore has a lot of heart problems, but I don't know the exact mortality rate.\"],\n",
       " '6/10': [\"According to the Ministry of Health's 2019 statistics, ischemic heart disease accounts for nearly 19% of total mortality in Singapore.\",\n",
       "  'In 2019, ischemic heart disease was responsible for approximately 19% of all deaths in Singapore, as reported by the Ministry of Health.',\n",
       "  \"The Ministry of Health's 2019 data indicates that ischemic heart disease contributes to around 19% of total mortality in Singapore.\",\n",
       "  'Ischemic heart disease is a leading cause of death in Singapore, accounting for around 19% of total mortality in 2019, according to the Ministry of Health.',\n",
       "  'In Singapore, ischemic heart disease was attributed to around 19% of total deaths in 2019, based on national health statistics from the Ministry of Health.'],\n",
       " '8.5/10': ['According to national health statistics from the Ministry of Health in 2019, ischemic heart disease accounts for approximately 19% of total mortality in Singapore.',\n",
       "  'In 2019, the Ministry of Health reported that ischemic heart disease was responsible for around 18.5% of total deaths in Singapore.',\n",
       "  'National health statistics from the Ministry of Health in 2019 indicate that ischemic heart disease contributes to roughly 19.2% of total mortality in Singapore.',\n",
       "  \"The Ministry of Health's 2019 national health statistics show that ischemic heart disease is responsible for about 18.9% of total deaths in Singapore.\",\n",
       "  \"As of 2019, ischemic heart disease was attributed to around 19.1% of total mortality in Singapore, according to the Ministry of Health's national health statistics.\"]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(index):\n",
    "    with open(\"../data/further_prompting/combined_data.json\", \"r\", encoding=\"utf-8\") as fin:\n",
    "        data = json.load(fin)\n",
    "        \n",
    "    return data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "Question:\n",
      "In what setting do the majority of cardiac arrests occur, according to a study conducted in Singapore in 2019?\n",
      "\n",
      "===================================\n",
      "User's Answer:\n",
      "Cardiac arrests usually happen in emergency rooms, right?\n",
      "\n",
      "===================================\n",
      "Guiding Question:\n",
      "Hmm, that's a good guess, but what about outside of the hospital setting? Are there any other places where cardiac arrests might be more likely to happen?\n",
      "\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "def extract_answer(answer, pattern=r'\"guiding_question\"\\s*:\\s*\"([^\"]+)\"'):\n",
    "    \"\"\"\n",
    "    Extracts the answer from the text associated with the key \"guiding_question\".\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input string to search for the guiding question.\n",
    "    \n",
    "    Returns:\n",
    "        str: The extracted guiding question or an error message.\n",
    "    \"\"\"\n",
    "    try:        \n",
    "        # Search for the pattern in the input text\n",
    "        match = re.search(pattern, answer)\n",
    "        \n",
    "        # If a match is found, return the captured group (the question)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            # If no match is found, return an error message\n",
    "            return \"No guiding question found in the input text.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        # If any unexpected error occurs, return a generic error message\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "        \n",
    "\n",
    "PROMPT = \\\n",
    "'''You are an expert in linguistic variation and medical communication. \n",
    "You are provided with a medical question, a persons answer to that question, and the model answer to that question. \n",
    "Your task is to generate a follow up question that aids the user in the answering of the question. \n",
    "You are to focus in on what is missing from the users answer in comparison to the model answer, and hint that to the user in the follow up question.\n",
    "You are to reply in a cheerful, friendly tone.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Users Answer:\n",
    "{user_ans}\n",
    "\n",
    "Model answer:\n",
    "{model_ans}\n",
    "\n",
    "The returning format should be like this:\n",
    "{{\"guiding_question\": \"Question to help the user better answer the question\"}}\n",
    "\n",
    "Before returning the answer, ensure and double check that the answer is in accordance to the format above.\n",
    "'''\n",
    "\n",
    "def generate_guiding_question(qn, user_ans, model_ans) -> str:\n",
    "    '''Generates the question used to re-prompt the user, \n",
    "    helping him to answer the question better with some hints'''\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "            template=PROMPT,\n",
    "            input_variables=[\"question\", \"user_ans\", \"model_ans\"]\n",
    "        ) \n",
    "    \n",
    "    final_prompt = prompt.format(question=qn, user_ans=user_ans, model_ans=model_ans)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "            model=CHAT_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": final_prompt\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=1024,\n",
    "            top_p=1,\n",
    "            stream=True,\n",
    "            stop=None\n",
    "        )\n",
    "\n",
    "    llm_answer = ''''''\n",
    "    for chunk in completion:\n",
    "        llm_answer += chunk.choices[0].delta.content or \"\"\n",
    "    # Improve error handling here\n",
    "    guiding_qn = extract_answer(llm_answer)\n",
    "    print(\"===================================\")\n",
    "    print(f\"Question:\\n{qn}\\n\")\n",
    "    print(\"===================================\")\n",
    "    print(f\"User's Answer:\\n{user_ans}\\n\")\n",
    "    print(\"===================================\")\n",
    "    print(f\"Guiding Question:\\n{guiding_qn}\\n\")\n",
    "    print(\"===================================\")\n",
    "    return guiding_qn\n",
    "\n",
    "data = load_data(1)\n",
    "model_ans = data['Answer']\n",
    "qn = data['Question']\n",
    "ans_index = 1\n",
    "user_ans = data['3/10'][ans_index]\n",
    "ans = generate_guiding_question(qn, user_ans, model_ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO for Ethan (Generate answer similarity pipeline)\n",
    "def get_answer_similarity(retry_ans, model_ans) -> float: \n",
    "    '''\n",
    "    Takes in the users retried answer and the model answer. \n",
    "    Uses finetuned cross encoder to generate similarity score\n",
    "    '''\n",
    "    score = None\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def re_prompt_user(guiding_qn) -> str:\n",
    "    '''Function to send the guiding question to the frontend from the backend AND retrieve answer from user'''\n",
    "    # Send the guiding question to the user\n",
    "    pass\n",
    "    \n",
    "def retrieve_retry_answer() -> str:\n",
    "    # receives the answer back from the user, prob a fetch from the backend or from frontend?\n",
    "    retry_ans = None\n",
    "    \n",
    "    return retry_ans\n",
    "\n",
    "\n",
    "\n",
    "def retry_pipeline(qn, user_ans, model_ans, threshold=0.7) -> dict:\n",
    "    status = {\"attempt\": \"FAIL\", \"retries\": 0}\n",
    "    \n",
    "    # number of retries set to 2\n",
    "    for i in range(1,3):\n",
    "        \n",
    "        # generate the guiding question with help of LLM\n",
    "        guiding_qn = generate_guiding_question(qn, user_ans, model_ans)\n",
    "        \n",
    "        # Send the guiding question to backend/ somewhere\n",
    "        re_prompt_user(guiding_qn)\n",
    "        \n",
    "        # retrieve the users retried answer\n",
    "        retry_ans = retrieve_retry_answer()\n",
    "            \n",
    "        # Compare with threshold\n",
    "        score = get_answer_similarity(retry_ans, model_ans)\n",
    "            \n",
    "        # if user passes this round\n",
    "        if score >= threshold:\n",
    "            status['attempt'] = \"PASS\"\n",
    "            return status  \n",
    "             \n",
    "        status['retries'] = i\n",
    "        \n",
    "    return status"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_buddy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
